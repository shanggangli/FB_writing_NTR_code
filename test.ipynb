{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "class args:\n",
    "    model_name = \"allenai/longformer-base-4096\"\n",
    "    max_length = 1024\n",
    "    input = \"../feedback-prize-2021/\"\n",
    "    \n",
    "target_id_map = {\n",
    "    \"B-Lead\": 0,\n",
    "    \"I-Lead\": 1,\n",
    "    \"B-Position\": 2,\n",
    "    \"I-Position\": 3,\n",
    "    \"B-Evidence\": 4,\n",
    "    \"I-Evidence\": 5,\n",
    "    \"B-Claim\": 6,\n",
    "    \"I-Claim\": 7,\n",
    "    \"B-Concluding Statement\": 8,\n",
    "    \"I-Concluding Statement\": 9,\n",
    "    \"B-Counterclaim\": 10,\n",
    "    \"I-Counterclaim\": 11,\n",
    "    \"B-Rebuttal\": 12,\n",
    "    \"I-Rebuttal\": 13\n",
    "}\n",
    "\n",
    "id_target_map = {v: k for k, v in target_id_map.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model_name)\n",
    "# Initializing a model from the configuration\n",
    "model = AutoModel.from_pretrained(args.model_name)\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self,model_name = None,num_labels = 1):\n",
    "        super(TextModel,self).__init__()\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)# 768\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "        self.drop_out1 = nn.Dropout(0.1)\n",
    "        self.drop_out2 = nn.Dropout(0.2)\n",
    "        self.drop_out3 = nn.Dropout(0.3)\n",
    "        self.drop_out4 = nn.Dropout(0.4)\n",
    "        self.drop_out5 = nn.Dropout(0.5)\n",
    "        self.output = nn.Linear(config.hidden_size,num_labels)\n",
    "\n",
    "        if 'deberta-v2-xxlarge' in model_name:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:24].requires_grad_(False) # 冻结24/48\n",
    "        if 'deberta-v2-xlarge' in model_name:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:14].requires_grad_(False) # 冻结12/24\n",
    "        \n",
    "        if 'funnel-transformer-xlarge' in model_name:\n",
    "            self.model.embeddings.requires_grad_(False)\n",
    "            self.model.encoder.layer[:1].requires_grad_(False) # 冻结1/3\n",
    "\n",
    "    def forward(self,input_ids,attention_mask,labels = None):\n",
    "        if 'gpt' in self.model.name_or_path:\n",
    "            emb = self.model(input_ids)[0]\n",
    "        else:\n",
    "            emb = self.model(input_ids,attention_mask)[0]\n",
    "\n",
    "        preds1 = self.output(self.dropout1(emb))\n",
    "        preds2 = self.output(self.dropout2(emb))\n",
    "        preds3 = self.output(self.dropout3(emb))\n",
    "        preds4 = self.output(self.dropout4(emb))\n",
    "        preds5 = self.output(self.dropout5(emb))\n",
    "        preds = (preds1 + preds2 + preds3 + preds4 + preds5) / 5\n",
    "\n",
    "        logits = torch.softmax(preds,dim = -1)\n",
    "        if labels is not None:\n",
    "            loss = self.get_loss(preds,labels,attention_mask)\n",
    "            return loss,logits\n",
    "        else:\n",
    "            return logits\n",
    "\n",
    "    def get_loss(self,outputs,targets,attention_mask):\n",
    "        loss_fct =nn.CrossEntropyLoss()\n",
    "\n",
    "        active_loss = attention_mask.reshape(-1) == 1\n",
    "        active_logits = outputs.reshape(-1,outputs.shape[-1])\n",
    "        true_labels = targets.reshape(-1)\n",
    "        idxs = np.where(active_loss.cpu().numpy()==1)[0]\n",
    "        active_logits = active_logits[idxs]\n",
    "        true_labels = true_labels[idxs].to(torch.long)\n",
    "\n",
    "        loss = loss_fct(active_logits,true_labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class FeedbackDataset:\n",
    "    def __init__(self, samples, max_len, tokenizer):\n",
    "        self.samples = samples\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.length = len(samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.samples[idx][\"input_ids\"]\n",
    "\n",
    "        # add start token id to the input_ids\n",
    "        input_ids = [self.tokenizer.cls_token_id] + input_ids\n",
    "\n",
    "        if len(input_ids) > self.max_len - 1:\n",
    "            input_ids = input_ids[: self.max_len - 1]\n",
    "\n",
    "        # add end token id to the input_ids\n",
    "        input_ids = input_ids + [self.tokenizer.sep_token_id]\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "\n",
    "        return {\n",
    "            \"ids\": input_ids,\n",
    "            \"mask\": attention_mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class Collate:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        output = dict()\n",
    "        output[\"ids\"] = [sample[\"ids\"] for sample in batch]\n",
    "        output[\"mask\"] = [sample[\"mask\"] for sample in batch]\n",
    "    \n",
    "        # convert to tensors\n",
    "        output[\"ids\"] = torch.tensor(output[\"ids\"], dtype=torch.long)\n",
    "        output[\"mask\"] = torch.tensor(output[\"mask\"], dtype=torch.long)\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "def prepare_df(arg, tokenizer, ids):\n",
    "    samples_df = []\n",
    "    for id_num in range(len(ids)):\n",
    "        if id_num%100==0: print(id_num,', ',end='')\n",
    "        n = ids[id_num]\n",
    "        name = f'../feedback-prize-2021/train/{n}.txt'\n",
    "        text = open(name, 'r').read()\n",
    "        \n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "                    text,\n",
    "                    return_offsets_mapping=True,\n",
    "                    truncation = True,\n",
    "                    max_length = arg.max_length,\n",
    "                    padding='max_length'\n",
    "                    )\n",
    "\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        attention_masks = encoded_text[\"attention_mask\"]\n",
    "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
    "\n",
    "        sample = {\n",
    "                \"id\": n,\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_masks\":attention_masks,\n",
    "                \"text\": text,\n",
    "                \"offset_mapping\": offset_mapping,\n",
    "                }\n",
    "\n",
    "        samples_df.append(sample)\n",
    "    return samples_df\n",
    "\n",
    "def train_and_eval():\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"../feedback-prize-2021/train.csv\")\n",
    "ids = train.id.unique()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(args.model)\n",
    "test_samples = prepare_df(args, tokenizer, ids)\n",
    "collate = Collate(tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "raw_preds = []\n",
    "for fold_ in range(5):\n",
    "    current_idx = 0\n",
    "    test_dataset = FeedbackDataset(test_samples, args.max_len, tokenizer)\n",
    "    model = TextModel(model_name=args.model, num_labels=len(target_id_map) - 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LongformerBaseModelOutputWithPooling' object has no attribute 'start_logits'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\kaggle\\Feedback Prize - Evaluating Student Writing\\code\\test.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/kaggle/Feedback%20Prize%20-%20Evaluating%20Student%20Writing/code/test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m attention_mask \u001b[39m=\u001b[39m encoding[\u001b[39m\"\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Code/kaggle/Feedback%20Prize%20-%20Evaluating%20Student%20Writing/code/test.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(input_ids, attention_mask\u001b[39m=\u001b[39mattention_mask)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Code/kaggle/Feedback%20Prize%20-%20Evaluating%20Student%20Writing/code/test.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m start_logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39;49mstart_logits\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/Feedback%20Prize%20-%20Evaluating%20Student%20Writing/code/test.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m end_logits \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mend_logits\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Code/kaggle/Feedback%20Prize%20-%20Evaluating%20Student%20Writing/code/test.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m all_tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(input_ids[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LongformerBaseModelOutputWithPooling' object has no attribute 'start_logits'"
     ]
    }
   ],
   "source": [
    "\n",
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "encoding = tokenizer(question, text, return_tensors=\"pt\",return_offsets_mapping=True)\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "\n",
    "# default is local attention everywhere\n",
    "# the forward method will automatically set global attention on question tokens\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "outputs = model(input_ids, attention_mask=attention_mask)\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n",
    "\n",
    "answer_tokens = all_tokens[torch.argmax(start_logits) : torch.argmax(end_logits) + 1]\n",
    "answer = tokenizer.decode(\n",
    "    tokenizer.convert_tokens_to_ids(answer_tokens)\n",
    ")  # remove space prepending space token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 875/15594 [00:19<05:21, 45.83it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (18882 > 4096). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 15594/15594 [05:39<00:00, 45.95it/s]\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "train = pd.read_csv(\"../feedback-prize-2021/train.csv\")\n",
    "ids = train.id.unique()\n",
    "\n",
    "def prepare_df(args, tokenizer, df, train_ids):\n",
    "    training_samples = []\n",
    "    for idx in tqdm(train_ids):\n",
    "        name = args.input +'train/{idx}.txt'\n",
    "        text = open(name, 'r').read()\n",
    "    \n",
    "        encoded_text = tokenizer.encode_plus(\n",
    "                    text,\n",
    "                    add_special_tokens=False,\n",
    "                    return_offsets_mapping=True\n",
    "                    )\n",
    "\n",
    "        input_ids = encoded_text[\"input_ids\"]\n",
    "        input_labels = copy.deepcopy(input_ids)\n",
    "        offset_mapping = encoded_text[\"offset_mapping\"]\n",
    "\n",
    "        for k in range(len(input_labels)):\n",
    "            input_labels[k] = \"O\"\n",
    "\n",
    "        sample = {\n",
    "                \"id\": idx,\n",
    "                \"input_ids\": input_ids,\n",
    "                \"text\": text,\n",
    "                \"offset_mapping\": offset_mapping,\n",
    "                }\n",
    "\n",
    "        temp_df = df[df[\"id\"] == idx]\n",
    "\n",
    "        for _, row in temp_df.iterrows():\n",
    "            text_labels = [0] * len(text)\n",
    "            discourse_start = int(row[\"discourse_start\"])\n",
    "            discourse_end = int(row[\"discourse_end\"])\n",
    "            prediction_label = row[\"discourse_type\"]\n",
    "            text_labels[discourse_start:discourse_end] = [1] * (discourse_end - discourse_start)\n",
    "            target_idx = []\n",
    "            for map_idx, (offset1, offset2) in enumerate(encoded_text[\"offset_mapping\"]):\n",
    "                if sum(text_labels[offset1:offset2]) > 0:\n",
    "                    if len(text[offset1:offset2].split()) > 0:\n",
    "                        target_idx.append(map_idx)\n",
    "\n",
    "            targets_start = target_idx[0]\n",
    "            targets_end = target_idx[-1]\n",
    "            pred_start = \"B-\" + prediction_label\n",
    "            pred_end = \"I-\" + prediction_label\n",
    "            input_labels[targets_start] = pred_start\n",
    "            input_labels[targets_start + 1 : targets_end + 1] = [pred_end] * (targets_end - targets_start)\n",
    "\n",
    "        sample[\"input_ids\"] = input_ids\n",
    "        sample[\"input_labels\"] = input_labels\n",
    "        training_samples.append(sample)\n",
    "    return training_samples\n",
    "\n",
    "a = prepare_df(args,tokenizer,train,ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'I-Lead',\n",
       " 'B-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'I-Position',\n",
       " 'B-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'B-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'I-Claim',\n",
       " 'B-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'I-Evidence',\n",
       " 'B-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'I-Concluding Statement',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][\"input_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Many', 'Ġpeople', 'Ġbelieve', 'Ġthat', 'Ġthe', 'ĠElectoral', 'ĠCollege', 'Ġshould', 'Ġbe', 'Ġabolished', ',', '</s>']\n",
      "[(0, 0), (0, 4), (5, 11), (12, 19), (20, 24), (25, 28), (29, 38), (39, 46), (47, 53), (54, 56), (57, 66), (66, 67), (0, 0)]\n",
      "hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\noffset_mapping  记录的是tokenizer后的token与原来的关系\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    " \n",
    " \n",
    "MODELNAME=\"bert-base-chinese\"\n",
    " \n",
    "text = \"Many people believe that the Electoral College should be abolished,\"\n",
    "tokens = tokenizer.tokenize(text,add_special_tokens=True)\n",
    "outputs = tokenizer.encode_plus(text, return_offsets_mapping=True, add_special_tokens=True)  #add_special_tokens=True 添加 [cls] [sep]等标志\n",
    "token_span=outputs[\"offset_mapping\"]\n",
    "print(tokens)\n",
    "print(token_span)\n",
    " \n",
    "print(\"hello\")\n",
    " \n",
    "'''\n",
    "offset_mapping  记录的是tokenizer后的token与原来的关系\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import pandas as pd\n",
    "df = pd.read_csv('../feedback-prize-2021/train.csv')\n",
    "kf = KFold(n_splits=5,random_state=42,shuffle=True)\n",
    "\n",
    "kf.get_n_splits(df)\n",
    "n = 1\n",
    "for train_index, test_index in kf.split(df):\n",
    "    df.loc[test_index,\"kfold\"] = int(n)\n",
    "    n +=1\n",
    "df[\"kfold\"] = df[\"kfold\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../feedback-prize-2021/df_n_fold.csv\",index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../feedback-prize-2021\\df_n_fold.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
